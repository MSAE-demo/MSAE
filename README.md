<h1><center>Masked Sparse Adversarial Examples for Audio-Visual Speech Recognition</center></h1>

<center><b>Anonymous Author(s)</b></center>

<center>Submission Id: 1514</center> 

## Abstract
Sparse adversarial attacks design imperceptible perturbations onto partial positions of inputs that lead a neural network model to predict incorrect outputs. Until now, most researches focus on the image classification and speech recognition domain. However, research on the adversarial attack against audio-visual speech recognition is limited and faces several challenges: 1) 'dispensable regions': some audio and video regions are less important for the model in the speech recognition process. Attacking these regions brings more noise while contributes less to constructing a successful adversarial example; 2) 'sensitiveness distinction': the perceptibility of humans towards the same noise under different regions is significantly different. Particularly, perturbations are more noticeable in the periods of silences and pauses; 3) 'temporal cues': the temporal information contained in videos should be explored. In this paper, we propose a novel sparse adversarial attack scheme, MSAE, that adopts weighted masks to overcome the difficulties above. Specifically, 1) we introduce grouped selective mask to achieve grouped sparsity through backpropagation automatically; 2) the perceptibility weight matrix is introduced to ensure the imperceptibility of the audio and video respectively; 3) we utilize $l2$-norm within frames and $l1$-norm across frames to achieve spatial and temporal sparsity. Experiments on the LRS2-BBC dataset demonstrate the effectiveness of MSAE: it achieves the lowest noise level among several state-of-the-art attack baselines even when only a portion of the input is perturbed. Moreover, our work is the first attempt to implement a successful sparse attack against the audio-visual speech recognition systems.

## Audio/Video Adversarial Examples
*Note: All samples are in LRS2-BBC dataset[1].*
Here We display two sets of audio examples and video examples of the audio-visual test in the paper. In each set, there is a clean example, adversarial examples generated by baselines in the paper and an imperceptible adversarial example generated with MSAE. Listen to and see them carefully and choose which one is the clean example.


### 1. Adversarial Examples for Audio-Visual Speech Recognition
Since the examples listed below is in the audio-visual test, the attack method in "()" means the corresponding audio attack mehtod.

**First Set: AND TURNING UPSTAIRS INTO AN OPEN PLAN AREA IS DEFINITELY THE WAY TO GO  -->  EVERY SEPTEMBER THIS PLACE WOULD BE TRANSFORMED INTO WHAT WAS**
<div>
	<div style='text-align:center; display: inline-block;'>
	<video width="224" height="112" controls>
	  <source src="CW/1.mp4" type="video/mp4">
	  您的浏览器不支持 HTML5 video 标签。
	</video>
	<h4>CW + CW_l2</h4>
	</div>
	
	<div style='text-align:center; display: inline-block;'>
	<video width="224" height="112" controls>
	  <source src="CW_MSAE/1.mp4" type="video/mp4">
	  您的浏览器不支持 HTML5 video 标签。
	</video>
	<h4>CW + CW_l2 with MSAE</h4>
	</div>

	<div style='text-align:center; display: inline-block;'>
	<video width="224" height="112" controls>
	  <source src="IPC/1.mp4" type="video/mp4">
	  您的浏览器不支持 HTML5 video 标签。
	</video>
	<h4>IPC + CW_l2</h4>
	</div>
	
	<div style='text-align:center; display: inline-block;'>
	<video width="224" height="112" controls>
	  <source src="1.mp4" type="video/mp4">
	  您的浏览器不支持 HTML5 video 标签。
	</video>
	<h4>IPC + CW_l2 with MSAE</h4>
	</div>
	
	<div style='text-align:center; display: inline-block;'>
	<video width="224" height="112" controls>
	  <source src="Imperceptible/1.mp4" type="video/mp4">
	  您的浏览器不支持 HTML5 video 标签。
	</video>
	<h4>Imperceptible + CW_l2</h4>
	</div>
	
	<div style='text-align:center; display: inline-block;'>
	<video width="224" height="112" controls>
	  <source src="1.mp4" type="video/mp4">
	  您的浏览器不支持 HTML5 video 标签。
	</video>
	<h4>Imperceptible + CW_l2 with MSAE</h4>
	</div>
</div>



## References
[1] Afouras T, Chung J S, Senior A, et al. Deep audio-visual speech recognition[J]. IEEE transactions on pattern analysis and machine intelligence, 2018.

[2] Zhang H, Zhou P, Yan Q, et al. Generating robust audio adversarial examples with temporal dependency[C]//Proc. Int. Joint Conf. Artif. Intell. 2020: 1-5.

[3] Carlini N, Wagner D. Audio adversarial examples: Targeted attacks on speech-to-text[C]//2018 IEEE Security and Privacy Workshops (SPW). IEEE, 2018: 1-7.

[4] Carlini N, Wagner D. Towards evaluating the robustness of neural networks[C]//2017 ieee symposium on security and privacy (sp). IEEE, 2017: 39-57.